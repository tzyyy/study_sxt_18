# 回归算法

回归是统计学中最有力的工具之一。机器学习监督学习算法分为分类算法和回归算法两种，其实就是根据类别标签分布类型为离散型、连续性而定义的。回归算法用于连续型分布预测，针对的是数值型的样本，使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测连续型数据而不仅仅是离散的类别标签。

回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。那么什么是线性关系和非线性关系？

比如说在房价上，房子的面积和房子的价格有着明显的关系。那么X=房间大小，Y=房价，那么在坐标系中可以看到这些点：

那么通过一条直线把这个关系描述出来，叫线性关系

![房价线性](./images/房价线性.png)

如果是一条曲线，那么叫非线性关系

![房价非线性](./images/房价非线性.png)

那么回归的目的就是建立一个回归方程（函数）用来预测目标值，回归的求解就是求这个回归方程的回归系数。

# 一、回归算法之线性回归

线性回归的定义是：目标值预期是输入变量的线性组合。线性模型形式简单、易于建模，但却蕴含着机器学习中一些重要的基本思想。线性回归，是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。

> 优点：结果易于理解，计算不复杂
>
> 缺点：对非线性的数据拟合不好
>
> 适用数据类型：数值型和标称型

对于单变量线性回归，例如：前面房价例子中房子的大小预测房子的价格。**f(x) = w1\*x+w0**，这样通过主要参数w1就可以得出预测的值。

通用公式为：

h\left(\theta\right){=}\theta_0+\theta_1{x}h(θ)=θ0+θ1x

那么对于多变量回归，例如：瓜的好坏程度 **f(x) = w0+0.2色泽+0.5根蒂+0.3\*敲声**，得出的值来判断一个瓜的好与不好的程度。

通用公式为：

h\left(\theta\right){=}\theta_{0}+\theta_{1}{x_{1}}+\theta_{2}{x_{2}}h(θ)=θ0+θ1x1+θ2x2

线性模型中的向量W值，客观的表达了各属性在预测中的重要性，因此线性模型有很好的解释性。对于这种“多特征预测”也就是（多元线性回归），那么线性回归就是在这个基础上得到这些W的值，然后以这些值来建立模型，预测测试数据。简单的来说就是学得一个线性模型以尽可能准确的预测实值输出标记。

那么如果对于多变量线性回归来说我们可以通过向量的方式来表示W值与特征X值之间的关系：

\theta = \begin{pmatrix}\theta_0 \\\theta_1 \\\theta_2 \\\theta_3\end{pmatrix}θ=⎝⎜⎜⎛θ0θ1θ2θ3⎠⎟⎟⎞ X = \begin{pmatrix}x_0\\x_1\\x_2\\x_3\end{pmatrix}X=⎝⎜⎜⎛x0x1x2x3⎠⎟⎟⎞

两向量相乘，结果为一个整数是估计值,其中所有特征集合的第一个特征值x_0x0=1,那么我们可以通过通用的向量公式来表示线性模型：

h(\theta) = \theta^T * xh(θ)=θT∗x

一个列向量的转置与特征的乘积，得出我们预测的结果，但是显然我们这个模型得到的结果可定会有误差，如下图所示：

**单变量**

![房价误差](./images/房价误差.png)

**多变量**

![多变量回归误差](./images/多变量回归误差.png)

**损失函数**

损失函数是一个贯穿整个机器学习重要的一个概念，大部分机器学习算法都会有误差，我们得通过显性的公式来描述这个误差，并且将这个误差优化到最小值。

对于线性回归模型，将模型与数据点之间的距离差之和做为衡量匹配好坏的标准，误差越小,匹配程度越大。我们要找的模型就是需要将f(x)和我们的真实值之间最相似的状态。于是我们就有了误差公式，模型与数据差的平方和最小：

J\left(\theta\right){=}\sum_{i=1}^{m} \left({h_\theta}({x}^{(i)}){-}{y}^{(i)}\right)^{2}J(θ)=∑i=1m(hθ(x(i))−y(i))2

上面公式定义了所有的误差和，那么现在需要使这个值最小？那么有两种方法，**一种使用梯度下降算法**，**另一种使正规方程解法（只适用于简单的线性回归）**。

**梯度下降算法**

上面误差公式是一个通式，我们取两个单个变量来求最小值，误差和可以表示为：

cost\left({w_0+w_1x_1}\right){=}\sum_{i=1}^{N} \left({w_0+w_1x_i}{-}{y_i}\right)^{2}cost(w0+w1x1)=∑i=1N(w0+w1xi−yi)2

可以通过调整不同的w_1w1和w_0w0的值，就能使误差不断变化，而当你找到这个公式的最小值时，你就能得到最好的w_1w1,w_0w0 而这对\left({w_1},{w_0}\right)(w1,w0)就是能最好描述你数据关系的模型参数。

怎么找cost\left({w_0+w_1x_1}\right)cost(w0+w1x1)的最小? cost\left({w_0+w_1x_1}\right)cost(w0+w1x1)的图像其实像一个山谷一样，有一个最低点。找这个最低点的办法就是，先随便找一个点(w_1w1=5, w_0w0=4), 然后 沿着这个碗下降的方向找，最后就能找到山谷的最低点。

![梯度下降](./images/梯度下降.png)

### 1、LinearRegression

**sklearn.linear_model.LinearRegression**

```python
class LinearRegression(fit_intercept = True，normalize = False，copy_X = True，n_jobs = 1)
  """
  :param normalize:如果设置为True时，数据进行标准化。请在使用normalize = False的估计器调时用fit之前使用preprocessing.StandardScaler

  :param copy_X:boolean，可选，默认为True，如果为True，则X将被复制

  :param n_jobs：int，可选，默认1。用于计算的CPU核数
  """
```

实例代码：

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
```

#### 1.方法

**fit(X,y,sample_weight = None)**

使用X作为训练数据拟合模型，y作为X的类别值。X，y为数组或者矩阵

```python
reg.fit ([[0, 0], [1, 1], [2, 2]], [0, 1, 2])
```

**predict(X)**

预测提供的数据对应的结果

```python
reg.predict([[3,3]])

array([ 3.])
```

#### 2.属性

**coef_**

表示回归系数w=(w1,w2..)

```python
reg.coef_

array([ 0.5,  0.5])
```

**intercept_** 表示w0

**加入交叉验证**

前面我们已经提到了模型的交叉验证，那么我们这个自己去建立数据集，然后通过线性回归的交叉验证得到模型。由于sklearn中另外两种回归岭回归、lasso回归都本省提供了回归CV方法，比如linear_model.Lasso，交叉验证linear_model.LassoCV；linear_model.Ridge，交叉验证linear_model.RidgeCV。所以我们需要通过前面的cross_validation提供的方法进行k-折交叉验证。

```python
from sklearn.datasets.samples_generator import make_regression
from sklearn.model_selection import cross_val_score
from sklearn import linear_model
import matplotlib.pyplot as plt

lr = linear_model.LinearRegression()
X, y = make_regression(n_samples=200, n_features=5000, random_state=0)
result = cross_val_score(lr, X, y)
print result
```

# 3、线性回归案例分析

**波士顿房价预测**

使用scikit-learn中内置的回归模型对“美国波士顿房价”数据进行预测。对于一些比赛数据，可以从kaggle官网上获取，网址：<https://www.kaggle.com/datasets>

**1.美国波士顿地区房价数据描述**

```python
from sklearn.datasets import load_boston

boston = load_boston()

print boston.DESCR
```

**2.波士顿地区房价数据分割**

```python
from sklearn.cross_validation import train_test_split
import numpy as np
X = boston.data
y = boston.target

X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=33,test_size = 0.25)
```

**3.训练与测试数据标准化处理**

```python
from sklearn.preprocessing import StandardScaler
ss_X = StandardScaler()
ss_y = StandardScaler()

X_train = ss_X.fit_transform(X_train)
X_test = ss_X.transform(X_test)
y_train = ss_X.fit_transform(y_train)
X_train = ss_X.transform(y_test)
```

**4.使用最简单的线性回归模型LinearRegression和梯度下降估计SGDRegressor对房价进行预测**

```python
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train,y_train)
lr_y_predict = lr.predict(X_test)

from sklearn.linear_model import SGDRegressor
sgdr = SGDRegressor()
sgdr.fit(X_train,y_train)
sgdr_y_predict = sgdr.predict(X_test)
```

**5.性能评测**

对于不同的类别预测，我们不能苛刻的要求回归预测的数值结果要严格的与真实值相同。一般情况下，我们希望衡量预测值与真实值之间的差距。因此，可以测评函数进行评价。其中最为直观的评价指标均方误差(Mean Squared Error)MSE，因为这也是线性回归模型所要优化的目标。

MSE的计算方法如式：

{MSE=}\frac{1}{m}\sum_{i=1}^{m}\left({y^{i}-\bar{y}}\right)^{2}MSE=m1∑i=1m(yi−y¯)2

**使用MSE评价机制对两种模型的回归性能作出评价**

```python
from sklearn.metrics import mean_squared_error

print '线性回归模型的均方误差为：',mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_tranform(lr_y_predict))
print '梯度下降模型的均方误差为：',mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_tranform(sgdr_y_predict))
```

通过这一比较发现，使用梯度下降估计参数的方法在性能表现上不及使用解析方法的LinearRegression，但是如果面对训练数据规模十分庞大的任务，随即梯度法不论是在分类还是回归问题上都表现的十分高效，可以在不损失过多性能的前提下，节省大量计算时间。根据Scikit-learn光网的建议，如果数据规模超过10万，推荐使用随机梯度法估计参数模型。

> 注意：线性回归器是最为简单、易用的回归模型。正式因为其对特征与回归目标之间的线性假设，从某种程度上说也局限了其应用范围。特别是，现实生活中的许多实例数据的各种特征与回归目标之间，绝大多数不能保证严格的线性关系。尽管如此，在不清楚特征之间关系的前提下，我们仍然可以使用线性回归模型作为大多数数据分析的基线系统。

完整代码如下：

```python
from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_boston
from sklearn.cross_validation import train_test_split
from sklearn.metrics import mean_squared_error,classification_report
from sklearn.cluster import KMeans


def linearmodel():
    """
    线性回归对波士顿数据集处理
    :return: None
    """

    # 1、加载数据集

    ld = load_boston()

    x_train,x_test,y_train,y_test = train_test_split(ld.data,ld.target,test_size=0.25)

    # 2、标准化处理

    # 特征值处理
    std_x = StandardScaler()
    x_train = std_x.fit_transform(x_train)
    x_test = std_x.transform(x_test)


    # 目标值进行处理

    std_y  = StandardScaler()
    y_train = std_y.fit_transform(y_train)
    y_test = std_y.transform(y_test)

    # 3、估计器流程

    # LinearRegression
    lr = LinearRegression()

    lr.fit(x_train,y_train)

    # print(lr.coef_)

    y_lr_predict = lr.predict(x_test)

    y_lr_predict = std_y.inverse_transform(y_lr_predict)

    print("Lr预测值：",y_lr_predict)


    # SGDRegressor
    sgd = SGDRegressor()

    sgd.fit(x_train,y_train)

    # print(sgd.coef_)

    y_sgd_predict = sgd.predict(x_test)

    y_sgd_predict = std_y.inverse_transform(y_sgd_predict)

    print("SGD预测值：",y_sgd_predict)

    # 带有正则化的岭回归

    rd = Ridge(alpha=0.01)

    rd.fit(x_train,y_train)

    y_rd_predict = rd.predict(x_test)

    y_rd_predict = std_y.inverse_transform(y_rd_predict)

    print(rd.coef_)

    # 两种模型评估结果

    print("lr的均方误差为：",mean_squared_error(std_y.inverse_transform(y_test),y_lr_predict))

    print("SGD的均方误差为：",mean_squared_error(std_y.inverse_transform(y_test),y_sgd_predict))

    print("Ridge的均方误差为：",mean_squared_error(std_y.inverse_transform(y_test),y_rd_predict))

    return None
```

## 1、欠拟合与过拟合

机器学习中的泛化，泛化即是，模型学习到的概念在它处于学习的过程中时模型没有遇见过的样本时候的表现。在机器学习领域中，当我们讨论一个机器学习模型学习和泛化的好坏时，我们通常使用术语：过拟合和欠拟合。我们知道模型训练和测试的时候有两套数据，训练集和测试集。在对训练数据进行拟合时，需要照顾到每个点，而其中有一些噪点，当某个模型过度的学习训练数据中的细节和噪音，以至于模型在新的数据上表现很差，这样的话模型容易复杂，拟合程度较高，造成过拟合。而相反如果值描绘了一部分数据那么模型复杂度过于简单，欠拟合指的是模型在训练和预测时表现都不好的情况，称为欠拟合。

我们来看一下线性回归中拟合的几种情况图示：

![欠拟合](./images/欠拟合.png)

\theta_0+\theta_1{x}θ0+θ1x

![拟合程度较好](./images/拟合程度较好.png)

\theta_{0}+\theta_{1}{x}+\theta_{2}x^{2}θ0+θ1x+θ2x2

![过拟合](./images/过拟合.png)

\theta_{0}+\theta_{1}{x}+\theta_{2}x^{2}+\theta_{3}x^{3}+\theta_{4}x^{4}θ0+θ1x+θ2x2+θ3x3+θ4x4

还有在逻辑回归分类中的拟合情况：

![LR欠拟合](./images/LR欠拟合.png)

![LR拟合程度较好](./images/LR拟合程度较好.png)

![LR过拟合](./images/LR过拟合.png)

**解决过拟合的方法**

在线性回归中，对于特征集过小的情况，容易造成欠拟合（underfitting），对于特征集过大的情况，容易造成过拟合（overfitting）。针对这两种情况有了更好的解决办法

**欠拟合**

欠拟合指的是模型在训练和预测时表现都不好的情况，欠拟合通常不被讨论，因为给定一个评估模型表现的指标的情况下，欠拟合很容易被发现。矫正方法是继续学习并且试着更换机器学习算法。

**过拟合**

对于过拟合，特征集合数目过多，我们需要做的是尽量不让回归系数数量变多，对拟合（损失函数）加以限制。

（1）当然解决过拟合的问题可以减少特征数，显然这只是权宜之计，因为特征意味着信息，放弃特征也就等同于丢弃信息，要知道，特征的获取往往也是艰苦卓绝的。

（2）引入了 **正则化** 概念。

**直观上来看，如果我们想要解决上面回归中的过拟合问题，我们最好就要消除x_3x3和x_4x4的影响，也就是想让\theta_3{,}\theta_4θ3,θ4都等于0，一个简单的方法就是我们对\theta_3{,}\theta_4θ3,θ4进行惩罚，增加一个很大的系数，这样在优化的过程中就会使这两个参数为零。**



# 二、回归算法之岭回归

具有L2正则化的线性最小二乘法。岭回归是一种专用于共线性数据分析的有偏估计回归方法，实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价获得回归系数更为符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。当数据集中存在共线性的时候，岭回归就会有用。

## 1、sklearn.linear_model.Ridge

```python
class sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)**
  """
  :param alpha:float类型，正规化的程度
  """
from sklearn.linear_model import Ridge
clf = Ridge(alpha=1.0)
clf.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1]))
```

### 1.1方法

**score(X, y, sample_weight=None)**

```python
clf.score()
```

### 1.2属性

**coef_**

```python
clf.coef_
array([ 0.34545455,  0.34545455])
```

**intercept_**

```python
clf.intercept_
0.13636..
```

## 2、岭回归案例分析

```python
def linearmodel():
    """
    线性回归对波士顿数据集处理
    :return: None
    """

    # 1、加载数据集

    ld = load_boston()

    x_train,x_test,y_train,y_test = train_test_split(ld.data,ld.target,test_size=0.25)

    # 2、标准化处理

    # 特征值处理
    std_x = StandardScaler()
    x_train = std_x.fit_transform(x_train)
    x_test = std_x.transform(x_test)


    # 目标值进行处理

    std_y  = StandardScaler()
    y_train = std_y.fit_transform(y_train)
    y_test = std_y.transform(y_test)

    # 3、估计器流程

    # LinearRegression
    lr = LinearRegression()

    lr.fit(x_train,y_train)

    # print(lr.coef_)

    y_lr_predict = lr.predict(x_test)

    y_lr_predict = std_y.inverse_transform(y_lr_predict)

    print("Lr预测值：",y_lr_predict)


    # SGDRegressor
    sgd = SGDRegressor()

    sgd.fit(x_train,y_train)

    # print(sgd.coef_)

    y_sgd_predict = sgd.predict(x_test)

    y_sgd_predict = std_y.inverse_transform(y_sgd_predict)

    print("SGD预测值：",y_sgd_predict)

    # 带有正则化的岭回归

    rd = Ridge(alpha=0.01)

    rd.fit(x_train,y_train)

    y_rd_predict = rd.predict(x_test)

    y_rd_predict = std_y.inverse_transform(y_rd_predict)

    print(rd.coef_)

    # 两种模型评估结果

    print("lr的均方误差为：",mean_squared_error(std_y.inverse_transform(y_test),y_lr_predict))

    print("SGD的均方误差为：",mean_squared_error(std_y.inverse_transform(y_test),y_sgd_predict))

    print("Ridge的均方误差为：",mean_squared_error(std_y.inverse_transform(y_test),y_rd_predict))

    return None
```

# 三、聚类算法学习之k-means

### 1、K-Means类概述

在scikit-learn中，包括两个K-Means的算法，一个是传统的K-Means算法，对应的类是KMeans。另一个是基于采样的Mini Batch K-Means算法，对应的类是MiniBatchKMeans。一般来说，使用K-Means的算法调参是比较简单的。

用KMeans类的话，一般要注意的仅仅就是k值的选择，即参数n_clusters；如果是用MiniBatchKMeans的话，也仅仅多了需要注意调参的参数batch_size，即我们的Mini Batch的大小。

当然KMeans类和MiniBatchKMeans类可以选择的参数还有不少，但是大多不需要怎么去调参。下面我们就看看KMeans类和MiniBatchKMeans类的一些主要参数。

### 2. KMeans类主要参数

KMeans类的主要参数有：

1) **n_clusters**: 即我们的k值，一般需要多试一些值以获得较好的聚类效果。k值好坏的评估标准在下面会讲。

2）**max_iter**： 最大的迭代次数，一般如果是凸数据集的话可以不管这个值，如果数据集不是凸的，可能很难收敛，此时可以指定最大的迭代次数让算法可以及时退出循环。

3）**n_init：**用不同的初始化质心运行算法的次数。由于K-Means是结果受初始值影响的局部最优的迭代算法，因此需要多跑几次以选择一个较好的聚类效果，默认是10，一般不需要改。如果你的k值较大，则可以适当增大这个值。

4）**init：** 即初始值选择的方式，可以为完全随机选择'random',优化过的'k-means++'或者自己指定初始化的k个质心。一般建议使用默认的'k-means++'。

5）**algorithm**：有“auto”, “full” or “elkan”三种选择。"full"就是我们传统的K-Means算法， “elkan”是我们原理篇讲的elkan K-Means算法。默认的"auto"则会根据数据值是否是稀疏的，来决定如何选择"full"和“elkan”。一般数据是稠密的，那么就是 “elkan”，否则就是"full"。一般来说建议直接用默认的"auto"

### 3. MiniBatchKMeans类主要参数

MiniBatchKMeans类的主要参数比KMeans类稍多，主要有：

1) **n_clusters**: 即我们的k值，和KMeans类的n_clusters意义一样。

2）**max_iter：**最大的迭代次数， 和KMeans类的max_iter意义一样。

3）**n_init：**用不同的初始化质心运行算法的次数。这里和KMeans类意义稍有不同，KMeans类里的n_init是用同样的训练集数据来跑不同的初始化质心从而运行算法。而MiniBatchKMeans类的n_init则是每次用不一样的采样数据集来跑不同的初始化质心运行算法。

4）**batch_size**：即用来跑Mini Batch KMeans算法的采样集的大小，默认是100.如果发现数据集的类别较多或者噪音点较多，需要增加这个值以达到较好的聚类效果。

5）**init：** 即初始值选择的方式，和KMeans类的init意义一样。

6）**init_size:** 用来做质心初始值候选的样本个数，默认是batch_size的3倍，一般用默认值就可以了。

7）**reassignment_ratio:** 某个类别质心被重新赋值的最大次数比例，这个和max_iter一样是为了控制算法运行时间的。这个比例是占样本总数的比例，乘以样本总数就得到了每个类别质心可以重新赋值的次数。如果取值较高的话算法收敛时间可能会增加，尤其是那些暂时拥有样本数较少的质心。默认是0.01。如果数据量不是超大的话，比如1w以下，建议使用默认值。如果数据量超过1w，类别又比较多，可能需要适当减少这个比例值。具体要根据训练集来决定。

8）**max_no_improvement：**即连续多少个Mini Batch没有改善聚类效果的话，就停止算法， 和reassignment_ratio， max_iter一样是为了控制算法运行时间的。默认是10.一般用默认值就足够了。

### 4. K值的评估标准

　　　　不像监督学习的分类问题和回归问题，我们的无监督聚类没有样本输出，也就没有比较直接的聚类评估方法。但是我们可以从簇内的稠密程度和簇间的离散程度来评估聚类的效果。常见的方法有轮廓系数Silhouette Coefficient和Calinski-Harabasz Index。个人比较喜欢Calinski-Harabasz Index，这个计算简单直接，得到的Calinski-Harabasz分数值ss越大则聚类效果越好。

Calinski-Harabasz分数值ss的数学计算公式是：

s(k)=tr(Bk)tr(Wk)m−kk−1s(k)=tr(Bk)tr(Wk)m−kk−1



其中m为训练集样本数，k为类别数。BkBk为类别之间的协方差矩阵，WkWk为类别内部数据的协方差矩阵。trtr为矩阵的迹。

也就是说，类别内部数据的协方差越小越好，类别之间的协方差越大越好，这样的Calinski-Harabasz分数会高。在scikit-learn中， Calinski-Harabasz Index对应的方法是metrics.calinski_harabaz_score.

### 5. K-Means应用实例

下面用一个实例来讲解用KMeans类和MiniBatchKMeans类来聚类。我们观察在不同的k值下Calinski-Harabasz分数。

首先我们随机创建一些二维数据作为训练集，选择二维特征数据，主要是方便可视化。代码如下：

```
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.datasets.samples_generator import make_blobs
# X为样本特征，Y为样本簇类别， 共1000个样本，每个样本4个特征，共4个簇，簇中心在[-1,-1], [0,0],[1,1], [2,2]， 簇方差分别为[0.4, 0.2, 0.2]
X, y = make_blobs(n_samples=1000, n_features=2, centers=[[-1,-1], [0,0], [1,1], [2,2]], cluster_std=[0.4, 0.2, 0.2, 0.2], 
                  random_state =9)
plt.scatter(X[:, 0], X[:, 1], marker='o')
plt.show()
```

从输出图可以我们看看我们创建的数据如下：

![img](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213143259370-1291177869.png) 

现在我们来用K-Means聚类方法来做聚类，首先选择k=2，代码如下：

```
from sklearn.cluster import KMeans
y_pred = KMeans(n_clusters=2, random_state=9).fit_predict(X)
plt.scatter(X[:, 0], X[:, 1], c=y_pred)
plt.show()
```

k=2聚类的效果图输出如下：

![img](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213143444854-1882584288.png) 

现在我们来看看我们用Calinski-Harabasz Index评估的聚类分数:

```
from sklearn import metrics
metrics.calinski_harabaz_score(X, y_pred)  
```

输出如下：

```
3116.1706763322227
```

现在k=3来看看聚类效果，代码如下：

```
from sklearn.cluster import KMeans
y_pred = KMeans(n_clusters=3, random_state=9).fit_predict(X)
plt.scatter(X[:, 0], X[:, 1], c=y_pred)
plt.show()　　
```

　　　　k=3的聚类的效果图输出如下：

![img](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213144007542-1923430558.png) 

现在我们来看看我们用Calinski-Harabaz Index评估的k=3时候聚类分数:

```
metrics.calinski_harabaz_score(X, y_pred)  
```

输出如下：

```
2931.625030199556
```

可见此时k=3的聚类分数比k=2还差。

现在我们看看k=4时候的聚类效果：

```python
from sklearn.cluster import KMeans
y_pred = KMeans(n_clusters=4, random_state=9).fit_predict(X)
plt.scatter(X[:, 0], X[:, 1], c=y_pred)
plt.show()
```

k=4的聚类的效果图输出如下：

![img](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213144309354-169800692.png) 

现在我们来看看我们用Calinski-Harabasz Index评估的k=4时候聚类分数:

```
metrics.calinski_harabaz_score(X, y_pred)  
```

输出如下：

```
5924.050613480169
```

可见k=4的聚类分数比k=2和k=3都要高，这也符合我们的预期，我们的随机数据集也就是4个簇。当特征维度大于2，我们无法直接可视化聚类效果来肉眼观察时，用Calinski-Harabaz Index评估是一个很实用的方法。

现在我们再看看用MiniBatchKMeans的效果，我们将batch size设置为200. 由于我们的4个簇都是凸的，所以其实batch size的值只要不是非常的小，对聚类的效果影响不大。

```
for index, k in enumerate((2,3,4,5)):
    plt.subplot(2,2,index+1)
    y_pred = MiniBatchKMeans(n_clusters=k, batch_size = 200, random_state=9).fit_predict(X)
    score= metrics.calinski_harabaz_score(X, y_pred)  
    plt.scatter(X[:, 0], X[:, 1], c=y_pred)
    plt.text(.99, .01, ('k=%d, score: %.2f' % (k,score)),
                 transform=plt.gca().transAxes, size=10,
                 horizontalalignment='right')
plt.show()
```

　　　对于k=2,3,4,5对应的输出图为：

![img](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213154105901-1056813722.png)

　　　　可见使用MiniBatchKMeans的聚类效果也不错，当然由于使用Mini Batch的原因，同样是k=4最优，KMeans类的Calinski-Harabasz Index分数为5924.05,而MiniBatchKMeans的分数稍微低一些，为5921.45。这个差异损耗并不大。

## K-Means聚类案列

```python
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans

def kmeans():
    """
    手写数字聚类过程
    :return: None
    """
    # 加载数据

    ld = load_digits()

    print(ld.target[:20])


    # 聚类
    km = KMeans(n_clusters=810)

    km.fit_transform(ld.data)

    print(km.labels_[:20])

    print(silhouette_score(ld.data,km.labels_))

    return None



if __name__=="__main__":
    kmeans()
```